{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook an ensembled model will be created and trained\n",
    "Ensembling is possible in two options:\n",
    "- Combine two RIS1 models, with that the second will receive an image from preceding time\n",
    "- Combine RIS1 and RIS2 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time \n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import cuda\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "\n",
    "import confinement_mode_classifier as cmc\n",
    "\n",
    "path = Path(os.getcwd())\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ris_option = 'RIS1'\n",
    "second_img_opt = 'RIS2'\n",
    "num_workers = 32\n",
    "num_epochs_for_fc = 10\n",
    "num_epochs_for_all_layers = 10\n",
    "batch_size = 16\n",
    "learning_rate_min = 0.001\n",
    "learning_rate_max = 0.01\n",
    "comment_for_model_name = ris_option + 'x' + second_img_opt  + f'{...}'\n",
    "\n",
    "first_model_path = f'{path}/runs/24-02-22, 14-36-03 RIS1, onecycleLR, extended dset_all_layers/model.pt'\n",
    "second_model_path = f'{path}/runs/24-02-22, 18-07-52 RIS2, onecycleLR, extended dset_all_layers/model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_usage = pd.read_csv(f'{path}/data/shot_usage.csv')\n",
    "shot_for_ris = shot_usage[shot_usage['used_for_ris1'] & shot_usage['used_for_ris2']]\n",
    "shot_numbers = shot_for_ris['shot']\n",
    "shots_for_testing = shot_for_ris[shot_for_ris['used_as'] == 'test']['shot']\n",
    "shots_for_validation = shot_for_ris[shot_for_ris['used_as'] == 'val']['shot']\n",
    "\n",
    "\n",
    "shot_df, test_df, val_df, train_df = cmc.load_and_split_dataframes(path, shot_numbers, \n",
    "                                                                   shots_for_testing, \n",
    "                                                                   shots_for_validation, use_ELMS=False)\n",
    "\n",
    "#Get dataloaders. second_img_opt='RIS1' indicates that two RIS1 models will be ensembled\n",
    "test_dataloader = cmc.get_dloader(test_df, path=path, batch_size=batch_size,\n",
    "                                   shuffle=False, balance_data=True, \n",
    "                                   ris_option=ris_option, second_img_opt=second_img_opt, \n",
    "                                   num_workers=num_workers)\n",
    "\n",
    "val_dataloader = cmc.get_dloader(val_df, path=path, batch_size=batch_size,\n",
    "                                   shuffle=False, balance_data=True, \n",
    "                                   ris_option=ris_option, second_img_opt=second_img_opt, \n",
    "                                   num_workers=num_workers)\n",
    "\n",
    "train_dataloader = cmc.get_dloader(train_df, path=path, batch_size=batch_size,\n",
    "                                   shuffle=False, balance_data=True, \n",
    "                                   ris_option=ris_option, second_img_opt=second_img_opt, \n",
    "                                   num_workers=num_workers)\n",
    "\n",
    "dataloaders = {'train':train_dataloader, 'val':val_dataloader}\n",
    "dataset_sizes = {x: len(dataloaders[x].dataset) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "pretrained_model = torchvision.models.resnet18(weights='IMAGENET1K_V1', )\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = pretrained_model.fc.in_features\n",
    "pretrained_model.fc = nn.Linear(num_ftrs, 2) #3 classes: L-mode, H-mode, ELM\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "\n",
    "#Load pretrained model. RIS1 in this case\n",
    "pretrained_model.load_state_dict(torch.load(first_model_path))\n",
    "\n",
    "\n",
    "#Load pretrained RIS2 model\n",
    "ris2_model = copy.deepcopy(pretrained_model)\n",
    "ris2_model.load_state_dict(torch.load(second_model_path))\n",
    "\n",
    "\n",
    "untrained_ensembled_model = cmc.TwoImagesModel(modelA=pretrained_model, modelB=ris2_model, hidden_units=30).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze all the weights except the classifier's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelA.fc.weight: requires_grad = True\n",
      "modelA.fc.bias: requires_grad = True\n",
      "modelB.fc.weight: requires_grad = True\n",
      "modelB.fc.bias: requires_grad = True\n",
      "classifier.0.weight: requires_grad = True\n",
      "classifier.0.bias: requires_grad = True\n",
      "classifier.2.weight: requires_grad = True\n",
      "classifier.2.bias: requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for name, param in untrained_ensembled_model.named_parameters():\n",
    "    # Check if the current parameter is part of the MLP\n",
    "    if 'classifier' in name or 'fc' in name or 'last_fully_connected' in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Verify that only the MLP parameters have requires_grad set to True\n",
    "for name, param in untrained_ensembled_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: requires_grad = {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp =  datetime.fromtimestamp(time.time()).strftime(\"%y-%m-%d, %H-%M-%S \") + comment_for_model_name\n",
    "writer = SummaryWriter(f'runs/{timestamp}_classifier_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = next(iter(train_dataloader))['img'].to(device).float()\n",
    "writer.add_graph(untrained_ensembled_model, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2562/2562 [05:19<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0468 Acc: 0.9866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [01:04<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.3270 Acc: 0.7987\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2562/2562 [05:19<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0308 Acc: 0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [01:04<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2196 Acc: 0.7980\n",
      "Epoch 3/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2562/2562 [05:19<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0269 Acc: 0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [01:04<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1463 Acc: 0.8041\n",
      "Epoch 4/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2562/2562 [05:20<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0290 Acc: 0.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [01:04<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.6495 Acc: 0.7890\n",
      "Epoch 5/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2562/2562 [05:19<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0276 Acc: 0.9894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [01:04<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5761 Acc: 0.8066\n",
      "Epoch 6/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2562/2562 [05:19<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0289 Acc: 0.9895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [01:04<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.3576 Acc: 0.8034\n",
      "Epoch 7/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2562/2562 [05:19<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0311 Acc: 0.9886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [01:04<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 2.0158 Acc: 0.7886\n",
      "Epoch 8/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2562/2562 [05:20<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0423 Acc: 0.9875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [01:04<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 6.4999 Acc: 0.8165\n",
      "Epoch 9/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2562/2562 [05:20<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0397 Acc: 0.9871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [01:04<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7669 Acc: 0.8103\n",
      "Epoch 10/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2562 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = torch.optim.Adam(untrained_ensembled_model.parameters(), lr=learning_rate_min) #pouzit adam\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate_max, total_steps=50) #!!!\n",
    "\n",
    "model_path = Path(f'{path}/runs/{timestamp}_classifier_training/model.pt')\n",
    "\n",
    "ensembled_model = cmc.train_model(untrained_ensembled_model, criterion, optimizer, exp_lr_scheduler, \n",
    "                       dataloaders, writer, dataset_sizes, num_epochs=num_epochs_for_fc, \n",
    "                       chkpt_path = model_path.with_name(f'{model_path.stem}_chkpt{model_path.suffix}'))\n",
    "\n",
    "torch.save(ensembled_model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train all the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/compass/Shared/Users/bogdanov/.venv/lib/python3.8/site-packages/torch/cuda/memory.py:329: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d0079009e047a0b73de9cbc2d31f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1129 Acc: 0.9773\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81c0145ccdc4f909c5e6df2f3ea8d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3720 Acc: 0.8913\n",
      "Epoch 2/6\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ccf0ef88e047d7ad56e022d9c383f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0470 Acc: 0.9870\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4c07496f8048048f1e3255a1f909b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.8909 Acc: 0.7913\n",
      "Epoch 3/6\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39c73b9d7204b8c9218c71842db03ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0215 Acc: 0.9932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cfb60eb1c24524856605763e8dd9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3452 Acc: 0.8666\n",
      "Epoch 4/6\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aff6abd349f429b9853626f6a05fc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0267 Acc: 0.9924\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cf1465fde54010a5c2df102789da76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4024 Acc: 0.8079\n",
      "Epoch 5/6\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07cf0ab12be34539b590bf3074226001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0305 Acc: 0.9917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10bedbaeaa7458f8a152ac656da381d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2661 Acc: 0.9095\n",
      "Epoch 6/6\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062e6fa9d28b4c199a7d3caa66e88aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0262 Acc: 0.9914\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50800bfdaeda4eeaad4199f34537bdb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3210 Acc: 0.8900\n",
      "Training complete in 93m 34s\n",
      "Best val Acc: 0.909478\n"
     ]
    }
   ],
   "source": [
    "# Clear cash\n",
    "if cuda.is_available():\n",
    "    # Do i have a single GPU?\n",
    "    cuda.empty_cache()\n",
    "    \n",
    "    # Do i have multiple GPUs?\n",
    "    for i in range(cuda.device_count()):\n",
    "        cuda.reset_max_memory_allocated(i)\n",
    "        cuda.empty_cache()\n",
    "\n",
    "writer = SummaryWriter(f'runs/{timestamp}_all_layers')\n",
    "\n",
    "#Unfreeze all layers\n",
    "for name, param in ensembled_model.named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "#Check that all parameters are being optimized\n",
    "for name, param in ensembled_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: requires_grad = {param.requires_grad}\")\n",
    "\n",
    "model_path = Path(f'{path}/runs/{timestamp}_all_layers/model.pt')\n",
    "\n",
    "ensembled_model = cmc.train_model(ensembled_model, criterion, optimizer, exp_lr_scheduler, \n",
    "                                  dataloaders, writer, dataset_sizes, num_epochs=num_epochs_for_all_layers,\n",
    "                                  chkpt_path=model_path.with_name(f'{model_path.stem}_chkpt{model_path.suffix}'))\n",
    "\n",
    "\n",
    "torch.save(ensembled_model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = cmc.test_model(f'{path}/runs/{timestamp}_all_layers/', ensembled_model, test_dataloader, max_batch=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bogdanov_VU_kernel 3.8.10",
   "language": "python",
   "name": "bogdanov_vu_3.8.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
