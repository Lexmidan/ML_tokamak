{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is under construction. \n",
    "\n",
    "- In this notebook a rather simple 1-D CNN is trained and tested on H-alpha diagnostics. \n",
    "- Later this 1-D CNN may be used as a supplementary model for the ensembled RIS1xRIS2 resp. RIS1xRIS1 model, which have poor performance in distinguishing H-modes from ELMs.\n",
    "\n",
    "\n",
    "- Functions written here will migrate to `confinement_mode_classifier.py` once tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "import re\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm\n",
    "import pytorch_lightning as pl\n",
    "import confinement_mode_classifier as cmc\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, WeightedRandomSampler\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix, F1Score, MulticlassPrecision, MulticlassRecall, MulticlassPrecisionRecallCurve, MulticlassROC\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from tempfile import TemporaryDirectory\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time \n",
    "from datetime import datetime\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(os.getcwd())\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "data_dir_path = f'{path}/data/LH_alpha'\n",
    "file_names = os.listdir(data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "#Time window for the diagnostics\n",
    "h_alpha_window = 50\n",
    "\n",
    "#Shots used in training\n",
    "shot_numbers = [re.search(r'shot_(\\d+)', file_name).group(1) for file_name in file_names]\n",
    "shots_for_testing = ['18130', '16773', '16534', '19094', '18133']\n",
    "shots_for_validation = ['16769', '19379', '18057', '18132']\n",
    "\n",
    "shot_df, test_df, val_df, train_df = cmc.load_and_split_dataframes(path,shot_numbers, shots_for_testing, shots_for_validation, use_ELMS=True)\n",
    "\n",
    "#Test dloader is not balanced -> testing the ability to define ELM as anomalies\n",
    "test_dataloader = cmc.get_dloader(test_df, path=path, batch_size=batch_size, \n",
    "                                    balance_data=False, only_halpha=True, \n",
    "                                    second_img_opt=None, shuffle=False,\n",
    "                                    h_alpha_window = h_alpha_window)\n",
    "\n",
    "val_dataloader = cmc.get_dloader(val_df, path=path, batch_size=batch_size, \n",
    "                                    balance_data=True, only_halpha=True, \n",
    "                                    second_img_opt=None, shuffle=False,\n",
    "                                    h_alpha_window = h_alpha_window)\n",
    "\n",
    "train_dataloader = cmc.get_dloader(train_df, path=path, batch_size=batch_size, \n",
    "                                    balance_data=True, only_halpha=True, \n",
    "                                    second_img_opt=None, shuffle=False,\n",
    "                                    h_alpha_window = h_alpha_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple1DCNN(nn.Module):\n",
    "    def __init__(self, num_classes=3, h_alpha_window=80):\n",
    "        super(Simple1DCNN, self).__init__()\n",
    "        # Define the 1D convolutional layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Define a fully connected layer for classification\n",
    "        self.fc = nn.Linear(in_features=32 * h_alpha_window, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply 1D convolutions\n",
    "        x = x.unsqueeze(1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        # Flatten the tensor for the fully connected layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Apply the fully connected layer and return the output\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This `train_model()` function is just a modified function copied from confinement_mode_classifier.py\n",
    "- The main difference resides in how the input data are parsed to the model (batch of all the diagnostics vs batch of just RIS imgs)\n",
    "- Will have to generalize all the models in order to use a single function for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler:lr_scheduler, dataloaders: dict,\n",
    "                 writer: SummaryWriter, dataset_sizes={'train':1, 'val':1}, num_epochs=25,\n",
    "                 chkpt_path=os.getcwd()):\n",
    "    since = time.time()\n",
    "\n",
    "\n",
    "    torch.save(model.state_dict(), chkpt_path)\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            num_of_samples = 0\n",
    "            running_batch = 0\n",
    "            # Iterate over data.\n",
    "            #TODO: eliminate the need in that dummy iterative for tensorboard part\n",
    "            for batch in tqdm(dataloaders[phase]):\n",
    "                \n",
    "                inputs = batch['h_alpha'].to(device).float() # #TODO: is it smart to convert double to float here? \n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                running_batch += 1\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs) #2D tensor with shape Batchsize*len(modes)\n",
    "                    #TODO: inputs.type. \n",
    "                    _, preds = torch.max(outputs, 1) #preds = 1D array of indicies of maximum values in row. ([2,1,2,1,2]) - third feature is largest in first sample, second in second...\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                num_of_samples += inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data) #How many correct answers\n",
    "                \n",
    "                \n",
    "                #tensorboard part\n",
    "                \n",
    "                if running_batch % int(len(dataloaders[phase])/10)==int(len(dataloaders[phase])/10)-1: \n",
    "                    # ...log the running loss\n",
    "                    \n",
    "                    #Training/validation loss\n",
    "                    writer.add_scalar(f'{phase}ing loss',\n",
    "                                    running_loss / num_of_samples,\n",
    "                                    epoch * len(dataloaders[phase]) + running_batch)\n",
    "                    \n",
    "                    #F1 metric\n",
    "                    writer.add_scalar(f'{phase}ing F1 metric',\n",
    "                                    F1Score(task=\"multiclass\", num_classes=3).to(device)(preds, labels),\n",
    "                                    epoch * len(dataloaders[phase]) + running_batch)\n",
    "                    \n",
    "                    #Precision recall\n",
    "                    writer.add_scalar(f'{phase}ing macro Precision', \n",
    "                                        MulticlassPrecision(num_classes=3).to(device)(preds, labels),\n",
    "                                        epoch * len(dataloaders[phase]) + running_batch)\n",
    "                    \n",
    "                    writer.add_scalar(f'{phase}ing macro Recall', \n",
    "                                        MulticlassRecall(num_classes=3).to(device)(preds, labels),\n",
    "                                        epoch * len(dataloaders[phase]) + running_batch)\n",
    "                    \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                writer.add_scalar(f'best_accuracy for epoch',\n",
    "                                    epoch_acc,\n",
    "                                    epoch)\n",
    "                writer.close()\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), chkpt_path)\n",
    "\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(chkpt_path))\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_cnn = Simple1DCNN(h_alpha_window=h_alpha_window)\n",
    "untrained_cnn = untrained_cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataloaders = {'train':train_dataloader, 'val':val_dataloader}\n",
    "dataset_sizes = {x: len(dataloaders[x].dataset) for x in ['train', 'val']}\n",
    "\n",
    "timestamp =  datetime.fromtimestamp(time.time()).strftime(\"%d_%m_%y-%H-%M \") + input('add comment: ')\n",
    "# create grid of images\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter(f'runs/{timestamp}_cnn')\n",
    "model_path = Path(f'{path}/runs/{timestamp}_cnn/model.pt')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = torch.optim.Adam(untrained_cnn.parameters(), lr=0.01) #pouzit adam\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "\n",
    "num_epochs = 16\n",
    "trained_cnn = train_model(untrained_cnn, criterion, optimizer, exp_lr_scheduler, \n",
    "                       dataloaders, writer, dataset_sizes, num_epochs=num_epochs, \n",
    "                       chkpt_path = model_path.with_name(f'{model_path.stem}_chkpt{model_path.suffix}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Again, `test_model()` is modified function from `cmc` \n",
    "- Again main difference is how the batch is processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(run_path, model: torchvision.models.resnet.ResNet, test_dataloader: DataLoader,\n",
    "                max_batch: int = 0, return_metrics: bool = True, comment: str =''):\n",
    "    '''\n",
    "    Takes model and dataloader and returns figure with confusion matrix, \n",
    "    dataframe with predictions, F1 metric value, precision, recall and accuracy\n",
    "\n",
    "    Args:\n",
    "        model: ResNet model\n",
    "        test_dataloader: DataLoader used for testing\n",
    "        max_batch: maximum number of bathces to use for testing. Set = 0 to use all batches in DataLoader\n",
    "        return_metrics: if True returns confusion matrix, F1, precision, recall and accuracy \n",
    "    \n",
    "    Returns: \n",
    "        preds: pd.DataFrame() pd.DataFrame with columns of predicted class, true class, frame time and confidence of the prediction\n",
    "        precision: MulticlassPrecision(num_classes=3)\n",
    "        recall: MulticlassRecall(num_classes=3)\n",
    "        accuracy: (TP+TN)/(TP+TN+FN+FP)\n",
    "        fig_confusion_matrix: MulticlassConfusionMatrix(num_classes=3)\n",
    "    '''\n",
    "    y_df = torch.tensor([])\n",
    "    y_hat_df = torch.tensor([])\n",
    "    preds = pd.DataFrame(columns=['shot', 'prediction', 'label', 'time', 'confidence', 'L_logit', 'H_logit', 'ELM_logit'])\n",
    "    pattern = re.compile(r'RIS1_(\\d+)_t=')\n",
    "    batch_index = 0 #iterator\n",
    "    for batch in tqdm(test_dataloader, desc='Processing batches'):\n",
    "        batch_index +=1\n",
    "        outputs, y_hat, confidence = cmc.images_to_probs(model, batch['h_alpha'].to(device).float())\n",
    "        y_hat = torch.tensor(y_hat)\n",
    "        y_df = torch.cat((y_df.int(), batch['label']), dim=0)\n",
    "        y_hat_df = torch.cat((y_hat_df, y_hat), dim=0)\n",
    "        shot_numbers = [int(pattern.search(path).group(1)) for path in batch['path']]\n",
    "\n",
    "        pred = pd.DataFrame({'shot': shot_numbers, 'prediction': y_hat.data, \n",
    "                            'label': batch['label'].data, 'time':batch['time'], \n",
    "                            'confidence': confidence,'L_logit': outputs[:,0].cpu(), \n",
    "                            'H_logit': outputs[:,1].cpu(), 'ELM_logit': outputs[:,2].cpu()})\n",
    "\n",
    "        preds = pd.concat([preds, pred],axis=0, ignore_index=True)\n",
    "\n",
    "        if max_batch!=0 and batch_index>max_batch:\n",
    "            break\n",
    "\n",
    "    if return_metrics:\n",
    "        softmax_out = torch.nn.functional.softmax(torch.tensor(preds[['L_logit','H_logit','ELM_logit']].values), dim=1)\n",
    "        #Confusion matrix\n",
    "        confusion_matrix_metric = MulticlassConfusionMatrix(num_classes=3)\n",
    "        confusion_matrix_metric.update(y_hat_df, y_df)\n",
    "        conf_matrix_fig, conf_matrix_ax  = confusion_matrix_metric.plot()\n",
    "        #F1\n",
    "        f1 = F1Score(task=\"multiclass\", num_classes=3)(y_hat_df, y_df)\n",
    "\n",
    "        #Precision\n",
    "        precision = MulticlassPrecision(num_classes=3)(y_hat_df, y_df)\n",
    "        recall = MulticlassRecall(num_classes=3)(y_hat_df, y_df)\n",
    "        #precision(logits_df, y_df.int())\n",
    "         #Precision_recall curve\n",
    "        pr_curve = MulticlassPrecisionRecallCurve(num_classes=3, thresholds=64)\n",
    "        pr_curve.update(softmax_out, y_df)\n",
    "        pr_curve_fig, pr_curve_ax = pr_curve.plot(score=True)\n",
    "        #ROC metric\n",
    "        mcroc = MulticlassROC(num_classes=3, thresholds=64)\n",
    "        mcroc.update(torch.tensor(preds[['L_logit', 'H_logit', 'ELM_logit']].values.astype(float)), y_df)\n",
    "        roc_fig, roc_ax = mcroc.plot(score=True)\n",
    "        #Accuracy\n",
    "        accuracy = len(preds[preds['prediction']==preds['label']])/len(preds)\n",
    "\n",
    "        textstr = '\\n'.join((\n",
    "            f'Whole test dset',\n",
    "            r'threshhold = 0.5:',\n",
    "            r'f1=%.2f' % (f1.item(), ),\n",
    "            r'precision=%.2f' % (precision.item(), ),\n",
    "            r'recall=%.2f' % (recall.item(), ),\n",
    "            r'accuracy=%.2f' % (accuracy, )))\n",
    "        # these are matplotlib.patch.Patch properties\n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "        \n",
    "        conf_matrix_ax.set_title(f'confusion matrix for whole test dset')\n",
    "        pr_curve_ax.set_title(f'pr_curve for whole test dset')\n",
    "        pr_curve_ax.set_xlabel('Precision')\n",
    "        pr_curve_ax.set_ylabel('Recall')\n",
    "        roc_ax.text(0.05, 0.3, textstr, fontsize=14, verticalalignment='bottom', bbox=props)\n",
    "        roc_ax.set_xlabel('FP Rate')\n",
    "        roc_ax.set_ylabel('TP Rate')\n",
    "\n",
    "\n",
    "        # Open the saved images using Pillow\n",
    "        roc_img = cmc.matplotlib_figure_to_pil_image(roc_fig)\n",
    "        conf_matrix_img = cmc.matplotlib_figure_to_pil_image(conf_matrix_fig)\n",
    "        pr_curve_img = cmc.matplotlib_figure_to_pil_image(pr_curve_fig)\n",
    "        combined_image = Image.new('RGB', (conf_matrix_img.width + pr_curve_img.width + roc_img.width,\\\n",
    "                                            conf_matrix_img.height))\n",
    "\n",
    "        # Paste the saved images into the combined image\n",
    "        combined_image.paste(conf_matrix_img, (0, 0))\n",
    "        combined_image.paste(roc_img, (conf_matrix_img.width, 0))\n",
    "        combined_image.paste(pr_curve_img, (roc_img.width+conf_matrix_img.width, 0))\n",
    "        \n",
    "        # Save the combined image\n",
    "        combined_image.save(f'{run_path}/metrics_for_whole_test_dset_{comment}.png')\n",
    "\n",
    "        return preds, (conf_matrix_fig, conf_matrix_ax), f1, precision, recall, accuracy, (pr_curve_fig, pr_curve_ax), (roc_fig, roc_ax)\n",
    "    else: \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = test_model(f'{path}/runs/16_01_24-19-12 50 dpoints_cnn', trained_cnn, test_dataloader, comment ='50 datapoints')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 [anaconda-2023.07]",
   "language": "python",
   "name": "python3.9-anaconda-2023.07"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
