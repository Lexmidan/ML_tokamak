{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix, F1Score, MulticlassPrecision, MulticlassRecall, MulticlassPrecisionRecallCurve, MulticlassROC\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "\n",
    "import confinement_mode_classifier as cmc\n",
    "import alt_models as am\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "signal_window = 320\n",
    "num_workers = 32\n",
    "signal_name = 'mc'\n",
    "batch_size = 512\n",
    "pl.seed_everything(42)\n",
    "path=os.getcwd()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "shot_usage = pd.read_csv(f'{path}/data/shot_usage.csv')\n",
    "shot_for_ris = shot_usage[shot_usage['used_for_alt']]\n",
    "shot_numbers = shot_for_ris['shot']\n",
    "\n",
    "shots_for_testing = shot_for_ris[shot_for_ris['used_as'] == 'test']['shot']\n",
    "shots_for_validation = shot_for_ris[shot_for_ris['used_as'] == 'val']['shot']\n",
    "shots_for_training = shot_for_ris[shot_for_ris['used_as'] == 'train']['shot']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'alt_models' from '/compass/Shared/Users/bogdanov/vyzkumny_ukol/alt_models.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(am)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_df300, test_df300, val_df300, train_df300 = am.split_df(path, shot_numbers,shots_for_training, shots_for_testing, shots_for_validation, use_ELMs=True, signal_name=signal_name, sampling_freq=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader300 = am.get_dloader(train_df300, batch_size=batch_size, \n",
    "                            balance_data=True, shuffle=False, \n",
    "                            signal_window=signal_window,\n",
    "                            signal_name=signal_name,\n",
    "                            num_workers=num_workers)\n",
    "val_dataloader300 = am.get_dloader(val_df300, batch_size=batch_size, \n",
    "                            balance_data=True, shuffle=False, \n",
    "                            signal_window=signal_window,\n",
    "                            signal_name=signal_name,\n",
    "                            num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor([0., 1., 2., 2., 1., 0., 0., 1., 1., 0., 2., 2., 0., 0., 0., 2., 0., 0.,\n",
       "         1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 2., 1., 0., 0., 0., 0., 2., 1.,\n",
       "         1., 0., 0., 0., 2., 1., 1., 2., 0., 2., 1., 1., 0., 2., 2., 0., 0., 0.,\n",
       "         0., 2., 0., 0., 0., 2., 0., 0., 2., 2., 0., 0., 0., 2., 2., 0., 1., 1.,\n",
       "         2., 0., 2., 2., 2., 1., 1., 2., 0., 2., 0., 1., 0., 1., 0., 2., 0., 2.,\n",
       "         0., 2., 0., 1., 1., 0., 0., 1., 1., 2., 0., 2., 1., 1., 0., 1., 1., 2.,\n",
       "         1., 1., 0., 1., 2., 1., 0., 1., 1., 1., 2., 1., 0., 0., 1., 1., 1., 2.,\n",
       "         2., 0., 2., 2., 1., 0., 1., 2., 2., 1., 0., 2., 0., 2., 2., 2., 1., 0.,\n",
       "         0., 2., 2., 1., 1., 1., 2., 1., 0., 2., 1., 0., 0., 0., 0., 2., 0., 1.,\n",
       "         1., 2., 2., 2., 0., 0., 2., 0., 2., 2., 0., 1., 1., 1., 1., 2., 0., 0.,\n",
       "         1., 2., 1., 1., 0., 2., 2., 0., 0., 2., 0., 0., 2., 1., 2., 0., 2., 1.,\n",
       "         2., 0., 0., 2., 0., 0., 2., 2., 1., 2., 0., 0., 0., 1., 0., 2., 2., 1.,\n",
       "         0., 2., 2., 0., 1., 0., 1., 0., 2., 1., 1., 1., 2., 2., 0., 0., 1., 1.,\n",
       "         0., 0., 0., 2., 0., 0., 2., 0., 2., 2., 0., 0., 2., 1., 1., 0., 1., 0.,\n",
       "         0., 2., 2., 0., 2., 0., 1., 0., 0., 2., 1., 2., 2., 0., 1., 0., 2., 1.,\n",
       "         2., 0., 0., 1., 1., 0., 0., 1., 2., 2., 2., 2., 0., 0., 0., 2., 0., 0.,\n",
       "         0., 2., 0., 0., 0., 1., 2., 0., 0., 2., 2., 2., 0., 2., 1., 0., 0., 2.,\n",
       "         0., 2., 0., 0., 1., 0., 0., 1., 1., 2., 0., 2., 2., 2., 0., 1., 1., 1.,\n",
       "         0., 0., 1., 1., 2., 1., 1., 1., 2., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
       "         2., 0., 0., 2., 1., 2., 2., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "         0., 2., 0., 0., 2., 1., 1., 1., 0., 0., 2., 1., 2., 0., 1., 2., 1., 2.,\n",
       "         0., 2., 1., 1., 2., 1., 0., 2., 0., 1., 2., 1., 0., 1., 0., 2., 1., 1.,\n",
       "         2., 1., 2., 2., 1., 0., 1., 1., 0., 2., 0., 1., 2., 2., 2., 2., 0., 2.,\n",
       "         2., 1., 0., 1., 0., 1., 2., 2., 1., 0., 0., 0., 0., 2., 2., 1., 1., 2.,\n",
       "         1., 0., 0., 2., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "         0., 2., 1., 0., 2., 2., 1., 1., 0., 1., 0., 0., 2., 1., 1., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 2., 0., 1., 1., 1., 1., 0., 0., 0., 2., 0., 2., 1., 1.,\n",
       "         1., 0., 2., 1., 1., 0., 2., 1., 0., 1., 2., 2., 0., 0., 2., 2., 1., 1.,\n",
       "         2., 2., 2., 1., 1., 2., 0., 1.]),\n",
       " 'time': tensor([1017.4640, 1165.9410, 1128.3825, 1076.6560, 1093.2355, 1098.9370,\n",
       "          969.5595, 1094.1420, 1066.4290, 1204.2695, 1072.3090, 1135.8690,\n",
       "         1239.9975, 1035.4995, 1044.8795, 1097.3445, 1151.5735, 1051.0675,\n",
       "         1118.2500, 1103.9840, 1181.2080, 1166.4520, 1075.3890, 1108.4710,\n",
       "         1150.9960, 1011.9410, 1116.7100, 1082.6620, 1163.6625, 1073.4605,\n",
       "         1401.5610, 1269.1070, 1068.0215, 1002.0465, 1086.1760, 1079.2985,\n",
       "         1167.4145,  969.0030, 1190.4165,  996.4640, 1138.9280, 1057.8750,\n",
       "         1164.3205, 1079.2845, 1351.2520, 1126.9825, 1162.0805, 1164.2470,\n",
       "          987.9835, 1065.5680, 1118.2150, 1127.6965, 1122.3765, 1235.4860,\n",
       "         1061.1335, 1198.0500, 1178.0545, 1223.1695, 1145.6935, 1091.5800,\n",
       "          962.2130,  980.9275, 1144.5665, 1075.6935, 1041.6945, 1030.4385,\n",
       "         1042.7550, 1137.8640, 1096.7565, 1059.2015, 1167.7435, 1067.6505,\n",
       "         1078.5460, 1072.8550, 1108.8805, 1078.2380, 1116.3565, 1118.4180,\n",
       "         1061.5955, 1093.0045, 1033.4520, 1111.6070, 1226.7535, 1133.3385,\n",
       "         1073.7125, 1076.5090, 1155.8470, 1121.9915, 1103.0705, 1098.7165,\n",
       "         1039.2585, 1113.1890,  977.2770, 1084.9195, 1094.5620, 1104.9570,\n",
       "          995.4035, 1113.5005, 1182.8775, 1186.5875, 1252.0165, 1084.0445,\n",
       "         1076.9675, 1078.3080,  976.4405, 1186.9935, 1155.3220, 1147.2020,\n",
       "         1105.9650, 1143.7125, 1305.6540, 1071.2205, 1210.6080, 1077.6640,\n",
       "         1130.3075, 1120.3150, 1109.2585, 1140.6710, 1065.3020, 1174.6595,\n",
       "         1161.4155, 1385.2195, 1069.0995, 1071.6440, 1089.3960, 1122.0720,\n",
       "         1124.7285, 1135.5610, 1102.9445, 1154.3350, 1092.4270, 1027.8730,\n",
       "         1140.8390, 1125.3655, 1090.3375, 1133.3420, 1055.8205, 1207.2445,\n",
       "         1110.1265, 1138.6340, 1176.9940, 1182.7830, 1143.3380, 1033.7880,\n",
       "         1408.5050, 1096.5710, 1140.0935, 1190.8610, 1072.7360, 1143.3520,\n",
       "         1065.4280, 1074.5070, 1030.5505, 1106.1330, 1147.9440, 1189.1145,\n",
       "         1075.4275, 1397.5430, 1305.8080, 1116.1150, 1052.6460, 1124.5185,\n",
       "         1101.4185, 1092.8085, 1099.4445, 1194.1405, 1059.2470, 1181.9920,\n",
       "         1141.4620, 1094.7475, 1105.6430, 1115.9120, 1208.4135, 1136.7440,\n",
       "         1109.0695, 1085.5740, 1132.1765, 1075.5115,  999.8415, 1046.5000,\n",
       "         1115.9680, 1151.7100, 1113.6230, 1121.6660, 1235.5350, 1159.4240,\n",
       "         1096.1335, 1201.6410, 1291.5805, 1117.1510, 1183.3430, 1082.5955,\n",
       "         1081.3215, 1143.7440, 1088.3705, 1013.7820, 1080.3275, 1152.5675,\n",
       "         1162.5740, 1286.7785, 1220.1315, 1125.7400, 1009.6870, 1023.4455,\n",
       "         1080.9680, 1092.3535, 1180.6060, 1086.7010, 1023.5435,  985.4180,\n",
       "         1252.8950, 1137.7835, 1010.2540, 1172.8990, 1123.9130, 1083.5720,\n",
       "         1088.5630, 1207.1115, 1151.8675,  974.2075, 1079.6695, 1155.9380,\n",
       "         1101.6040, 1010.6985, 1098.9370, 1063.1320, 1096.1930, 1138.0215,\n",
       "         1117.8475, 1078.7210, 1122.4850,  985.3690, 1102.7100, 1164.2645,\n",
       "          968.5725, 1219.6695, 1074.4650, 1091.4645, 1008.8855, 1100.0955,\n",
       "         1073.2645,  993.7200, 1147.4155, 1177.3475,  973.2940,  983.8745,\n",
       "         1109.1255, 1119.3980, 1075.3925, 1049.9615, 1069.5335, 1185.0615,\n",
       "          977.3540, 1069.8765, 1139.5160, 1055.5755, 1094.2680, 1250.9560,\n",
       "         1151.8605,  972.3315, 1231.1145, 1165.5140, 1106.5740, 1118.4425,\n",
       "         1099.2380, 1169.4375, 1124.4835, 1216.5335, 1137.5805, 1187.6515,\n",
       "         1101.1420, 1254.0710, 1005.1440, 1151.9935, 1087.1770, 1059.4080,\n",
       "         1222.4030, 1134.2975, 1111.3095, 1215.5955, 1172.0555, 1072.1340,\n",
       "         1271.7705,  991.7110, 1038.3800, 1089.8790, 1038.7545, 1046.4020,\n",
       "          981.2915, 1100.4945, 1145.4835, 1225.1785, 1307.0960, 1087.9715,\n",
       "         1062.4705,  986.8530, 1042.2860, 1152.7810, 1075.5780, 1215.7425,\n",
       "         1320.0845, 1105.8390, 1089.1230, 1043.3255, 1332.0790, 1115.9120,\n",
       "          981.9425, 1165.1850, 1185.0510, 1025.5630, 1119.7865, 1001.0385,\n",
       "         1031.3730, 1148.8435, 1154.2195, 1080.6810, 1331.1095, 1116.8325,\n",
       "         1092.0525, 1106.2205,  980.6720, 1143.3695, 1114.1655, 1214.1640,\n",
       "         1261.5120,  978.7785, 1103.9735, 1141.9765, 1078.0140, 1087.5585,\n",
       "         1079.1795, 1071.6825, 1214.6750, 1110.1510, 1174.0330, 1097.5405,\n",
       "         1165.6890, 1175.7970, 1120.3115, 1221.0345, 1075.0635, 1133.8915,\n",
       "         1116.2830, 1070.6045, 1247.4490, 1132.5965, 1200.7905, 1096.4275,\n",
       "         1132.3795, 1095.6330, 1037.8865,  992.7505, 1124.8860, 1295.1575,\n",
       "         1094.1525, 1197.3990, 1078.3220, 1135.8060, 1097.0050, 1102.2830,\n",
       "          967.1620, 1132.4705, 1297.7615,  979.0200, 1103.4135, 1071.9555,\n",
       "         1158.3110, 1162.6440, 1039.5000, 1281.1645, 1125.3305, 1201.8475,\n",
       "         1157.1945, 1088.7065, 1143.4605, 1159.0425, 1075.9560, 1125.4390,\n",
       "          988.5505, 1118.6805, 1119.3280, 1055.6315, 1135.9740, 1135.2670,\n",
       "         1133.3245, 1065.6170, 1037.8760, 1069.7470, 1088.8815, 1111.8030,\n",
       "         1247.3475, 1118.0050,  992.1030, 1166.6095, 1064.8505, 1157.5340,\n",
       "         1135.8200, 1139.1730, 1180.9700, 1139.9850, 1088.0275,  968.7510,\n",
       "         1115.4430, 1076.6525,  994.3255, 1175.7830, 1345.7080, 1092.6020,\n",
       "         1088.9130, 1101.2925, 1073.8070, 1078.7420, 1005.9980, 1119.9685,\n",
       "         1113.1470, 1150.0090, 1273.0585, 1115.3240, 1040.8825, 1117.1720,\n",
       "         1150.0370, 1140.0165, 1162.0140, 1016.1900,  962.8430, 1262.5305,\n",
       "         1282.9810, 1080.5095, 1082.2455, 1142.8900, 1179.1045, 1126.9335,\n",
       "         1160.7120,  966.9625, 1270.2270, 1118.2290, 1348.1685, 1076.6945,\n",
       "         1069.7680, 1065.8620, 1044.2950, 1120.1715, 1053.3565,  982.8455,\n",
       "         1072.9530, 1120.8155, 1156.7955, 1119.1320,  987.5355, 1026.7005,\n",
       "         1021.6010, 1215.3610, 1116.8150,  977.4940, 1164.0580, 1092.8645,\n",
       "         1166.7180, 1098.5870, 1059.6460, 1168.1845, 1038.3870,  996.2085,\n",
       "         1137.5210, 1124.1615, 1119.2160, 1213.9225, 1025.0520, 1043.3045,\n",
       "         1235.9795, 1178.3695, 1009.0325, 1040.5395, 1115.4955, 1084.2370,\n",
       "         1106.3220, 1085.8645, 1088.7345, 1142.1725, 1101.5900, 1251.8450,\n",
       "         1041.6455, 1125.7225,  976.7310, 1137.5420, 1115.3870, 1110.2175,\n",
       "         1077.8215, 1058.0010, 1152.2350, 1076.5755, 1128.2810, 1178.4395,\n",
       "         1145.7635, 1167.1485, 1056.7795, 1187.4555, 1106.7245, 1094.7580,\n",
       "         1017.5515, 1043.0070, 1099.5775, 1141.9695, 1071.2485, 1106.0805,\n",
       "         1155.8925, 1093.9215, 1165.0800, 1194.6900, 1198.6170, 1108.9400,\n",
       "          983.4930, 1090.9850], dtype=torch.float64),\n",
       " 'mc': tensor([[[-2.2527e+00, -9.7269e-01, -1.6375e+00,  ..., -3.2950e+00,\n",
       "            1.6954e-01,  3.0012e-01],\n",
       "          [-1.6341e+00, -5.3361e+00, -4.5302e+00,  ...,  3.0673e+00,\n",
       "            3.4730e+00,  4.3187e+00],\n",
       "          [ 1.5990e+01,  1.5255e+01,  3.1002e+01,  ..., -3.9824e+00,\n",
       "           -1.4733e+01, -1.6811e+00],\n",
       "          [-1.1987e+00, -4.4102e+00, -5.7727e+00,  ...,  4.9342e+00,\n",
       "            1.6823e+01,  1.2490e+01]],\n",
       " \n",
       "         [[ 3.5501e+00,  2.7599e+00, -2.1792e+00,  ...,  3.1571e+00,\n",
       "            4.9093e+00,  5.2995e-01],\n",
       "          [-6.2903e+01, -4.3459e+01, -7.9776e+00,  ..., -4.2095e+01,\n",
       "           -5.8726e+01, -5.5170e+01],\n",
       "          [ 5.7669e+02,  5.1812e+02,  3.4256e+02,  ..., -4.1987e+01,\n",
       "            1.8089e+02,  4.4406e+02],\n",
       "          [-4.5446e+01, -4.2226e+01, -2.7744e+01,  ..., -1.5224e+00,\n",
       "           -2.4406e+01, -4.5074e+01]],\n",
       " \n",
       "         [[-3.4197e+00, -1.3396e+00, -1.1097e+00,  ..., -4.6788e+00,\n",
       "           -3.1688e+00, -1.2699e+00],\n",
       "          [ 2.1400e+00,  3.0788e+00,  1.9923e+00,  ...,  4.7179e+00,\n",
       "            4.6390e+00,  4.5701e+00],\n",
       "          [ 1.0670e+00,  4.3987e+00,  1.7253e+01,  ...,  1.4482e+01,\n",
       "            1.9122e+01,  2.4414e+01],\n",
       "          [ 1.9996e+00, -3.7692e-01, -2.6387e+00,  ..., -1.1410e+00,\n",
       "           -2.4034e+00, -5.5257e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 4.0010e+00,  6.1488e-01,  2.8259e+00,  ...,  8.2329e+00,\n",
       "            6.7310e+00,  7.8148e+00],\n",
       "          [ 1.8938e+01,  2.9735e+01,  3.1151e+01,  ..., -8.4548e+00,\n",
       "           -9.7030e+00, -1.2986e+01],\n",
       "          [-3.2551e+02, -3.5903e+02, -2.8890e+02,  ...,  1.6381e+02,\n",
       "            1.7962e+02,  1.8242e+02],\n",
       "          [ 2.5087e+01,  2.7621e+01,  2.3764e+01,  ..., -2.8092e+01,\n",
       "           -1.8791e+01, -4.1479e+00]],\n",
       " \n",
       "         [[ 1.6347e+00,  6.7697e-01,  1.9776e+00,  ...,  2.6543e+00,\n",
       "            2.4304e+00,  2.6697e+00],\n",
       "          [-2.0321e+00, -4.5318e+00, -9.3606e+00,  ...,  1.6127e+00,\n",
       "           -7.6717e+00, -6.3420e+00],\n",
       "          [ 7.0259e+00,  1.1365e+01,  6.8270e+00,  ...,  8.6732e+00,\n",
       "            1.0126e+01,  9.2257e+00],\n",
       "          [-3.8798e-01, -1.8580e-01, -8.4653e-01,  ..., -5.1452e-01,\n",
       "           -1.4084e+00, -1.0010e+00]],\n",
       " \n",
       "         [[-4.0354e+00, -1.5783e+00, -1.9474e+00,  ...,  1.1594e+00,\n",
       "           -8.1067e-01, -1.7822e+00],\n",
       "          [ 7.4804e-01, -1.2912e+00, -4.5633e-01,  ..., -1.7084e+00,\n",
       "           -2.0534e+00, -1.6674e+00],\n",
       "          [-4.8289e+01, -2.5107e+00, -7.6135e+01,  ...,  2.1257e+01,\n",
       "           -3.9889e+00, -9.6719e+00],\n",
       "          [-7.0061e+00, -1.3784e+00, -4.4147e-01,  ..., -4.8685e+00,\n",
       "           -2.7512e+00, -2.8071e-01]]], dtype=torch.float64),\n",
       " 'shot': tensor([17839., 16987., 18463., 18279., 19263., 19244., 17677., 17839., 17854.,\n",
       "         18263., 19241., 19241., 18263., 18499., 17677., 19237., 18499., 18268.,\n",
       "         16989., 19083., 18200., 18200., 16987., 16987., 19244., 17854., 18127.,\n",
       "         17839., 18052., 18052., 17854., 18200., 18499., 18489., 19241., 16987.,\n",
       "         18200., 18268., 19244., 17839., 18266., 18200., 19393., 19241., 18263.,\n",
       "         17677., 18509., 18476., 19238., 18279., 17677., 18489., 18279., 19393.,\n",
       "         18052., 18263., 18499., 18127., 16532., 19238., 18127., 18509., 18263.,\n",
       "         18268., 18499., 19242., 19083., 17839., 18476., 19393., 18200., 16989.,\n",
       "         18509., 16532., 18476., 18509., 17839., 18200., 18509., 18463., 19083.,\n",
       "         17854., 19241., 19393., 18052., 19238., 16532., 17677., 19244., 19238.,\n",
       "         17677., 18279., 19263., 18200., 18476., 18489., 16989., 19263., 18263.,\n",
       "         18263., 19239., 18476., 19237., 18476., 18279., 18263., 18476., 18509.,\n",
       "         18266., 17854., 16532., 16987., 17854., 19239., 19242., 17677., 19263.,\n",
       "         18476., 18509., 17854., 18127., 18263., 19240., 19238., 18200., 19239.,\n",
       "         18052., 16532., 19241., 19241., 18279., 18268., 16989., 19242., 18279.,\n",
       "         19239., 19238., 17854., 17677., 18509., 18263., 17854., 18263., 18476.,\n",
       "         18263., 18279., 18266., 18509., 17839., 18499., 19239., 18266., 18499.,\n",
       "         19238., 18463., 19239., 19083., 18263., 17854., 19263., 18279., 18127.,\n",
       "         19242., 19237., 19263., 19393., 18463., 17839., 18509., 19393., 19239.,\n",
       "         19241., 18200., 17677., 16987., 16987., 18266., 18509., 18463., 18266.,\n",
       "         19239., 19239., 18127., 18509., 18509., 16987., 19238., 18200., 18509.,\n",
       "         18279., 16987., 18488., 18263., 17854., 19239., 18200., 19239., 17854.,\n",
       "         19241., 18200., 16532., 18052., 19393., 19241., 19240., 19241., 18263.,\n",
       "         18263., 19240., 16532., 17854., 18200., 18476., 19241., 18266., 19240.,\n",
       "         18268., 17854., 19239., 19242., 19241., 16989., 17839., 19237., 19238.,\n",
       "         16989., 19242., 18476., 19239., 18266., 18279., 19083., 19241., 18476.,\n",
       "         16987., 19239., 19244., 19238., 16989., 18509., 18509., 17677., 18509.,\n",
       "         17854., 19244., 19238., 18279., 19263., 16987., 19083., 17839., 16987.,\n",
       "         17839., 18263., 18052., 18279., 18279., 16532., 18463., 18509., 19241.,\n",
       "         18463., 19241., 17677., 18279., 19083., 18052., 18127., 18476., 17677.,\n",
       "         19239., 18200., 18052., 17677., 19242., 17839., 18499., 19239., 19238.,\n",
       "         17854., 17854., 18279., 18200., 18499., 18476., 18263., 19241., 16987.,\n",
       "         18279., 18279., 19083., 18509., 17854., 18476., 19263., 16532., 19083.,\n",
       "         19239., 19241., 17854., 17854., 18268., 16987., 18476., 18263., 18266.,\n",
       "         18476., 18509., 16532., 19083., 19242., 18463., 17677., 18263., 18463.,\n",
       "         19242., 18263., 18279., 19240., 18279., 17677., 18200., 18476., 17854.,\n",
       "         18200., 19240., 18263., 18263., 16987., 16989., 18279., 19238., 17854.,\n",
       "         18266., 19393., 17677., 17677., 18263., 19240., 18509., 19238., 18463.,\n",
       "         17839., 18127., 18509., 19239., 17854., 19239., 18266., 17677., 16532.,\n",
       "         19237., 18463., 18509., 18200., 18509., 18488., 18476., 19393., 18268.,\n",
       "         18463., 18266., 17677., 19239., 18463., 17854., 19393., 16987., 18266.,\n",
       "         18200., 18266., 19239., 19239., 18127., 18200., 18509., 16987., 18052.,\n",
       "         16532., 19242., 16989., 16989., 18266., 18463., 18489., 18266., 18127.,\n",
       "         18266., 18476., 16987., 19241., 17677., 19393., 17854., 16987., 18476.,\n",
       "         19239., 18200., 17854., 18266., 19239., 18488., 18268., 16987., 17677.,\n",
       "         17854., 17854., 19263., 19263., 19238., 19241., 18266., 16532., 18266.,\n",
       "         18279., 17677., 18200., 19241., 17854., 17839., 19239., 18476., 19241.,\n",
       "         18268., 18127., 16532., 18509., 19239., 19241., 18476., 17677., 17677.,\n",
       "         18052., 18488., 16532., 17854., 18263., 18489., 19239., 18509., 18463.,\n",
       "         16989., 18499., 19393., 18263., 19242., 18476., 16532., 18489., 18499.,\n",
       "         19240., 17854., 19238., 19242., 18052., 19240., 18200., 18263., 19237.,\n",
       "         18476., 19242., 19239., 18463., 19238., 17839., 19241., 19244., 19083.,\n",
       "         19241., 18200., 18266., 16989., 19238., 18488., 17839., 18200., 17839.,\n",
       "         18200., 16532., 19241., 19242., 18052., 19083., 18476., 16989., 18266.,\n",
       "         18268., 18127., 17854., 16987., 16989., 18127., 18509., 18509., 18263.,\n",
       "         17854., 18476., 19239., 19241., 19244., 19242., 18509., 18263., 16987.,\n",
       "         18476., 18476., 17854., 18127., 18127., 18476., 18052., 19237.],\n",
       "        dtype=torch.float64)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1814262/3775638985.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  a = np.log(0)\n",
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1814262/3775638985.py\", line 11, in <module>\n",
      "    raise ValueError(\"Log of zero is undefined\")\n",
      "ValueError: Log of zero is undefined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import traceback\n",
    "import numpy as np\n",
    "\n",
    "log_file = \"./runs/logs/exception.log\"\n",
    "logging.basicConfig(filename=log_file, level=logging.ERROR)\n",
    "\n",
    "try:\n",
    "    a = np.log(0)\n",
    "    if np.isneginf(a):\n",
    "        raise ValueError(\"Log of zero is undefined\")\n",
    "except Exception as e:\n",
    "    logging.error(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "division by zero\n"
     ]
    }
   ],
   "source": [
    "file_path = './runs/logs/exception.log'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "    print(content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bogdanov_VU_kernel 3.8.10",
   "language": "python",
   "name": "bogdanov_vu_3.8.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
