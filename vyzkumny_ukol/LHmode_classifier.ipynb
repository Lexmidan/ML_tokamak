{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L-mode H-mode Classifier\n",
    "- In this notebook a single camera model will be created and trained. \n",
    "- First import ResNet model, modify its fc. layer and train this fc.layer\n",
    "- Then train the whole model\n",
    "- We can either train the model on imgs from RIS1 camera or RIS2, and then ensemble these models in `ModelEnsembling.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import confinement_mode_classifier as cmc\n",
    "from datetime import datetime\n",
    "import time \n",
    "import re\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(os.getcwd())\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "#Where are csv spreadsheets with time, mode, img_path, h_alpha columns are saved\n",
    "data_dir_path = f'{path}/data/LH_alpha'\n",
    "file_names = os.listdir(data_dir_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose shots, which will be used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_numbers = [re.search(r'shot_(\\d+)', file_name).group(1) for file_name in file_names]\n",
    "removed_shots = ['13182', '20009','20112', '20143', '20145', '20146', '20147', '16989', '16987', '20144']\n",
    "shot_numbers = [valid_shot for valid_shot in shot_numbers if valid_shot not in removed_shots]\n",
    "\n",
    "shots_for_testing = ['18130', '16773', '16534', '19094', '18133']\n",
    "shots_for_validation = ['16769', '19379', '18057', '18132']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloader\n",
    "- It is convinient to have dloaders in dictionary in order to easily switch between training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "shot_df, test_df, val_df, train_df = cmc.load_and_split_dataframes(path,shot_numbers, shots_for_testing, shots_for_validation, \n",
    "                                                                   use_ELMS=False)\n",
    "\n",
    "\n",
    "test_dataloader = cmc.get_dloader(test_df, path=path, batch_size=batch_size, ris_option='RIS2', balance_data=True, shuffle=False)\n",
    "val_dataloader = cmc.get_dloader(val_df, path=path, batch_size=batch_size, ris_option='RIS2', balance_data=True, shuffle=False)\n",
    "train_dataloader = cmc.get_dloader(train_df, path=path, batch_size=batch_size, ris_option='RIS2', balance_data=True, shuffle=False)\n",
    "\n",
    "dataloaders = {'train':train_dataloader, 'val':val_dataloader}\n",
    "dataset_sizes = {x: len(dataloaders[x].dataset) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time stamp will be added to the model's folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp =  datetime.fromtimestamp(time.time()).strftime(\"%d-%m-%y, %H-%M-%S \") + input('add comment: ')\n",
    "writer = SummaryWriter(f'runs/{timestamp}_last_fc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ResNet pretrained model\n",
    " And freeze all layers except last f.c. layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = torchvision.models.resnet18(weights='IMAGENET1K_V1', )\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    " \n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = pretrained_model.fc.in_features\n",
    "pretrained_model.fc = nn.Linear(num_ftrs, 3) #3 classes: L-mode, H-mode, ELM\n",
    "pretrained_model = pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train last fc of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "036d54f57fa14a1a97a278580f170c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2526 Acc: 0.9054\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7baeb369374e4dcf912440bf7a363eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2087 Acc: 0.9243\n",
      "Epoch 2/2\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee9e52eeeab49b7b9b7ee00849f4b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1346 Acc: 0.9481\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf644c12870542fbbe29dd4d84ae90a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2172 Acc: 0.9158\n",
      "Training complete in 24m 44s\n",
      "Best val Acc: 0.924301\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = torch.optim.Adam(pretrained_model.parameters(), lr=0.001) #pouzit adam\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "#Model will be saved to this folder along with metrics and tensorboard scalars\n",
    "model_path = Path(f'{path}/runs/{timestamp}_last_fc/model_fc_trained.pt')\n",
    "\n",
    "num_epochs = 2\n",
    "model = cmc.train_model(pretrained_model, criterion, optimizer, exp_lr_scheduler, \n",
    "                       dataloaders, writer, dataset_sizes, num_epochs=num_epochs, \n",
    "                       chkpt_path=model_path.with_name(f'{model_path.stem}_chkpt{model_path.suffix}'))\n",
    "\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f'runs/{timestamp}_all_layers')\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model_path = Path(f'{path}/runs/{timestamp}_all_layers/model_fully_trained.pt')\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "model = cmc.train_model(pretrained_model, criterion, optimizer, exp_lr_scheduler, \n",
    "                        dataloaders, writer, dataset_sizes, num_epochs=6,\n",
    "                        chkpt_path=model_path.with_name(f'{model_path.stem}_chkpt{model_path.suffix}'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with all layers trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a874308d87d8455da48e7abd7a41d0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "metrics = cmc.test_model(f'runs/{timestamp}', model, test_dataloader, comment='all_layers')\n",
    "\n",
    "# writer.add_figure(f'Confusion matrix for the model with trained f.c. layer', fig_confusion_matrix)\n",
    "# writer.add_scalar(f'Accuracy on test_dataset with trained f.c. layer', accuracy)\n",
    "# writer.add_scalar(f'F1 metric on test_dataset with trained f.c. layer', f1)\n",
    "# writer.add_scalar(f'Precision on test_dataset with trained f.c. layer', precision)\n",
    "# writer.add_scalar(f'Recall on test_dataset with trained f.c. layer', recall)\n",
    "# writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bogdanov_VU_kernel 3.8.10",
   "language": "python",
   "name": "bogdanov_vu_3.8.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
