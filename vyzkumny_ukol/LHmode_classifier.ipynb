{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L-mode H-mode  Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import confinement_mode_classifier as cmc\n",
    "from datetime import datetime\n",
    "import time \n",
    "import torchvision\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(os.getcwd())\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "shots = [16534, 16769, 16773, 18130, 19237, 19240, 19379, 18057, 16989]\n",
    "shots_for_testing = [16769, 18130, 18057]\n",
    "shots_for_validation = [19237]\n",
    "\n",
    "shot_df, test_df, val_df, train_df = cmc.load_and_split_dataframes(path,shots, shots_for_testing, shots_for_validation )\n",
    "\n",
    "\n",
    "test_dataloader = cmc.get_dloader(test_df, path=path, batch_size=batch_size)\n",
    "val_dataloader = cmc.get_dloader(val_df, path=path, batch_size=batch_size)\n",
    "train_dataloader = cmc.get_dloader(train_df, path=path, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time mode                      filename   shot\n",
      "0      960.2    0   imgs/RIS1_16534_t=960.2.png  16534\n",
      "1      960.4    0   imgs/RIS1_16534_t=960.4.png  16534\n",
      "2      960.6    0   imgs/RIS1_16534_t=960.6.png  16534\n",
      "3      960.8    0   imgs/RIS1_16534_t=960.8.png  16534\n",
      "4      961.0    0   imgs/RIS1_16534_t=961.0.png  16534\n",
      "...      ...  ...                           ...    ...\n",
      "8947  1097.4    1  imgs/RIS1_16989_t=1097.4.png  16989\n",
      "8948  1097.6    1  imgs/RIS1_16989_t=1097.6.png  16989\n",
      "8949  1097.8    1  imgs/RIS1_16989_t=1097.8.png  16989\n",
      "8950  1098.0    1  imgs/RIS1_16989_t=1098.0.png  16989\n",
      "8951  1098.2    1  imgs/RIS1_16989_t=1098.2.png  16989\n",
      "\n",
      "[8952 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloader, that will be used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train':train_dataloader, 'val':val_dataloader}\n",
    "dataset_sizes = {x: len(dataloaders[x].dataset) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp =  datetime.fromtimestamp(time.time()).strftime(\"%d-%m-%Y, %H-%M-%S \") + input('add comment: ')\n",
    "\n",
    "# create grid of images\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter(f'runs/{timestamp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import ResNet pretrained model\n",
    "### And freeze all layers except last f.c. layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = torchvision.models.resnet18(weights='IMAGENET1K_V1', )\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    " \n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = pretrained_model.fc.in_features\n",
    "pretrained_model.fc = nn.Linear(num_ftrs, 3) #3 classes: L-mode, H-mode, ELM\n",
    "pretrained_model = pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = torch.optim.Adam(pretrained_model.parameters(), lr=0.001) #pouzit adam\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train last fc of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "model = cmc.train_model(pretrained_model, criterion, optimizer, exp_lr_scheduler, \n",
    "                       dataloaders, writer, dataset_sizes, num_epochs=num_epochs, comment = 'fc training')\n",
    "model_path = Path(f'{path}/runs/{timestamp}/model_fc_trained.pt')\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with last fc trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df, fig_confusion_matrix, f1, precision, recall, accuracy = cmc.test_model(pretrained_model, test_dataloader, max_batch=50, return_metrics=True)\n",
    "\n",
    "writer.add_figure(f'Confusion matrix for the model with trained f.c. layer', fig_confusion_matrix)\n",
    "writer.add_scalar(f'Accuracy on test_dataset with trained f.c. layer', accuracy)\n",
    "writer.add_scalar(f'F1 metric on test_dataset with trained f.c. layer', f1)\n",
    "writer.add_scalar(f'Precision on test_dataset with trained f.c. layer', precision)\n",
    "writer.add_scalar(f'Recall on test_dataset with trained f.c. layer', recall)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "      <th>confidence</th>\n",
       "      <th>L_logit</th>\n",
       "      <th>H_logit</th>\n",
       "      <th>ELM_logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1346.4</td>\n",
       "      <td>0.635283</td>\n",
       "      <td>2.086415</td>\n",
       "      <td>1.529145</td>\n",
       "      <td>-4.535882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1225.4</td>\n",
       "      <td>0.990333</td>\n",
       "      <td>3.746156</td>\n",
       "      <td>-0.924853</td>\n",
       "      <td>-4.082767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1169.8</td>\n",
       "      <td>0.993942</td>\n",
       "      <td>-0.205450</td>\n",
       "      <td>4.900466</td>\n",
       "      <td>-5.373708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1117.2</td>\n",
       "      <td>0.765530</td>\n",
       "      <td>1.140892</td>\n",
       "      <td>2.328135</td>\n",
       "      <td>-4.378273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>962.0</td>\n",
       "      <td>0.926161</td>\n",
       "      <td>2.759862</td>\n",
       "      <td>0.216888</td>\n",
       "      <td>-4.058347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1194.2</td>\n",
       "      <td>0.983276</td>\n",
       "      <td>0.162354</td>\n",
       "      <td>4.241520</td>\n",
       "      <td>-5.115597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>0.998257</td>\n",
       "      <td>4.687540</td>\n",
       "      <td>-1.734702</td>\n",
       "      <td>-4.336363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>973.8</td>\n",
       "      <td>0.962574</td>\n",
       "      <td>3.388908</td>\n",
       "      <td>0.133559</td>\n",
       "      <td>-4.677454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1132.2</td>\n",
       "      <td>0.610902</td>\n",
       "      <td>1.499335</td>\n",
       "      <td>1.953208</td>\n",
       "      <td>-4.389137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1176.8</td>\n",
       "      <td>0.993149</td>\n",
       "      <td>-0.174894</td>\n",
       "      <td>4.807387</td>\n",
       "      <td>-5.318163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1664 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prediction label    time  confidence   L_logit   H_logit  ELM_logit\n",
       "0             0     0  1346.4    0.635283  2.086415  1.529145  -4.535882\n",
       "1             0     0  1225.4    0.990333  3.746156 -0.924853  -4.082767\n",
       "2             1     1  1169.8    0.993942 -0.205450  4.900466  -5.373708\n",
       "3             1     1  1117.2    0.765530  1.140892  2.328135  -4.378273\n",
       "4             0     0   962.0    0.926161  2.759862  0.216888  -4.058347\n",
       "...         ...   ...     ...         ...       ...       ...        ...\n",
       "1659          1     1  1194.2    0.983276  0.162354  4.241520  -5.115597\n",
       "1660          0     0  1292.0    0.998257  4.687540 -1.734702  -4.336363\n",
       "1661          0     0   973.8    0.962574  3.388908  0.133559  -4.677454\n",
       "1662          1     1  1132.2    0.610902  1.499335  1.953208  -4.389137\n",
       "1663          1     1  1176.8    0.993149 -0.174894  4.807387  -5.318163\n",
       "\n",
       "[1664 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9099)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9148)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9097)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9098557692307693"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m      2\u001b[0m     param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m cmc\u001b[38;5;241m.\u001b[39mtrain_model(pretrained_model, criterion, optimizer, exp_lr_scheduler, \n\u001b[1;32m      4\u001b[0m                         dataloaders, writer, dataset_sizes, num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs, comment \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "model = cmc.train_model(pretrained_model, criterion, optimizer, exp_lr_scheduler, \n",
    "                        dataloaders, writer, dataset_sizes, num_epochs=num_epochs, comment = 'fc training')\n",
    "model_path = Path(f'{path}/runs/{timestamp}/model_fully_trained.pt')\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with all layers trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, fig_confusion_matrix, f1, precision, recall, accuracy = cmc.test_model(model, test_dataloader, max_batch=50, return_metrics=True)\n",
    "\n",
    "writer.add_figure(f'Confusion matrix for the model with all layers trained', fig_confusion_matrix)\n",
    "writer.add_scalar(f'Accuracy on test_dataset with all layers trained', accuracy)\n",
    "writer.add_scalar(f'F1 metric on test_dataset with all layers trained', f1)\n",
    "writer.add_scalar(f'Precision on test_dataset with all layers trained', precision)\n",
    "writer.add_scalar(f'Recall on test_dataset with all layers trained', recall)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bogdanov_VU_kernel 3.8.10",
   "language": "python",
   "name": "bogdanov_vu_3.8.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
