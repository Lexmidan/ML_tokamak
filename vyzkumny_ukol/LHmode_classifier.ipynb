{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L-mode H-mode Classifier\n",
    "- In this notebook a single camera model will be created and trained. \n",
    "- First import ResNet model, modify its fc. layer and train this fc.layer\n",
    "- Then train the whole model\n",
    "- We can either train the model on imgs from RIS1 camera or RIS2, and then ensemble these models in `ModelEnsembling.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time \n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import cuda\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import confinement_mode_classifier as cmc\n",
    "\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(os.getcwd())\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "#Where are csv spreadsheets with time, mode, img_path, h_alpha columns are saved\n",
    "data_dir_path = f'{path}/data/LH_alpha'\n",
    "file_names = os.listdir(data_dir_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ris_option = 'RIS1'\n",
    "num_workers = 2\n",
    "num_epochs_for_fc = 10\n",
    "num_epochs_for_all_layers = 10\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "learning_rate_min = 0.001\n",
    "learning_rate_max = 0.01\n",
    "comment_for_model_name = ris_option + f'2 output classes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloader\n",
    "- It is convinient to have dloaders in dictionary in order to easily switch between training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_usage = pd.read_csv(f'{path}/data/shot_usage.csv')\n",
    "shot_for_ris = shot_usage[shot_usage['used_for_ris1'] if ris_option == 'RIS1' else shot_usage['used_for_ris2']]\n",
    "shot_numbers = shot_for_ris['shot']\n",
    "shots_for_testing = shot_for_ris[shot_for_ris['used_as'] == 'test']['shot']\n",
    "shots_for_validation = shot_for_ris[shot_for_ris['used_as'] == 'val']['shot']\n",
    "\n",
    "shot_df, test_df, val_df, train_df = cmc.load_and_split_dataframes(path,shot_numbers, shots_for_testing, \n",
    "                                                                   shots_for_validation, use_ELMS=False)\n",
    "\n",
    "\n",
    "test_dataloader = cmc.get_dloader(test_df, path, batch_size, \n",
    "                                    ris_option=ris_option, balance_data=False, \n",
    "                                    shuffle=False, num_workers=num_workers)\n",
    "\n",
    "val_dataloader = cmc.get_dloader(val_df, path, batch_size, \n",
    "                                    ris_option=ris_option, balance_data=True, \n",
    "                                    shuffle=False, num_workers=num_workers)\n",
    "\n",
    "train_dataloader = cmc.get_dloader(train_df, path, batch_size, \n",
    "                                    ris_option=ris_option, balance_data=True, \n",
    "                                    shuffle=False, num_workers=num_workers)\n",
    "\n",
    "dataloaders = {'train':train_dataloader, 'val':val_dataloader}\n",
    "dataset_sizes = {x: len(dataloaders[x].dataset) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time stamp will be added to the model's folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>mode</th>\n",
       "      <th>filename</th>\n",
       "      <th>h_alpha</th>\n",
       "      <th>shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [time, mode, filename, h_alpha, shot]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['shot'] == 18128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp =  datetime.fromtimestamp(time.time()).strftime(\"%y-%m-%d, %H-%M-%S \") + comment_for_model_name\n",
    "writer = SummaryWriter(f'runs/{timestamp}_last_fc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ResNet pretrained model\n",
    " And freeze all layers except last f.c. layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    " \n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = pretrained_model.fc.in_features\n",
    "pretrained_model.fc = nn.Linear(num_ftrs, num_classes) #3 classes: L-mode, H-mode, ELM\n",
    "pretrained_model = pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = next(iter(train_dataloader))['img']\n",
    "writer.add_graph(pretrained_model, sample_input.float().to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train last fc of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = torch.optim.Adam(pretrained_model.parameters(), lr=learning_rate_min)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate_max, total_steps=50) #!!!\n",
    "\n",
    "#Model will be saved to this folder along with metrics and tensorboard scalars\n",
    "model_path = Path(f'{path}/runs/{timestamp}_last_fc/model.pt')\n",
    "\n",
    "\n",
    "model = cmc.train_model(pretrained_model, criterion, optimizer, exp_lr_scheduler, \n",
    "                       dataloaders, writer, dataset_sizes, num_epochs=num_epochs_for_fc, \n",
    "                       chkpt_path=model_path.with_name(f'{model_path.stem}_chkpt{model_path.suffix}'))\n",
    "\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = cmc.test_model(f'runs/{timestamp}', model, test_dataloader, comment='all_layers')\n",
    "\n",
    "shots_for_testing = shots_for_testing.values.tolist()\n",
    "img_path = cmc.per_shot_test(path=f'{path}/runs/{timestamp}_last_fc/', \n",
    "                             shots=shots_for_testing, results_df=metrics['prediction_df'], writer=writer)\n",
    "\n",
    "writer.add_figure(f'Confusion matrix for the model with trained f.c. layer', metrics['confusion_matrix'][0])\n",
    "writer.add_figure(f'Confusion matrix for the model with trained f.c. layer', metrics['confusion_matrix'][0])\n",
    "writer.add_scalar(f'Accuracy on test_dataset with trained f.c. layer', metrics['accuracy'])\n",
    "writer.add_scalar(f'F1 metric on test_dataset with trained f.c. layer', metrics['f1'])\n",
    "writer.add_scalar(f'Precision on test_dataset with trained f.c. layer', metrics['precision'])\n",
    "writer.add_scalar(f'Recall on test_dataset with trained f.c. layer', metrics['recall'])\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f'runs/{timestamp}_all_layers')\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model_path = Path(f'{path}/runs/{timestamp}_all_layers/model.pt')\n",
    "\n",
    "\n",
    "\n",
    "model = cmc.train_model(model, criterion, optimizer, exp_lr_scheduler, \n",
    "                        dataloaders, writer, dataset_sizes, num_epochs=num_epochs_for_all_layers,\n",
    "                        chkpt_path=model_path.with_name(f'{model_path.stem}_chkpt{model_path.suffix}'))\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with all layers trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = cmc.test_model(f'runs/{timestamp}', model, test_dataloader, comment='all_layers')\n",
    "\n",
    "shots_for_testing = shots_for_testing.values.tolist()\n",
    "img_path = cmc.per_shot_test(path=f'{path}/runs/{timestamp}_last_fc/', \n",
    "                             shots=shots_for_testing, results_df=metrics['prediction_df'], writer=writer)\n",
    "\n",
    "writer.add_figure(f'Confusion matrix for the model with trained f.c. layer', metrics['confusion_matrix'][0])\n",
    "writer.add_figure(f'Confusion matrix for the model with trained f.c. layer', metrics['confusion_matrix'][0])\n",
    "writer.add_scalar(f'Accuracy on test_dataset with trained f.c. layer', metrics['accuracy'])\n",
    "writer.add_scalar(f'F1 metric on test_dataset with trained f.c. layer', metrics['f1'])\n",
    "writer.add_scalar(f'Precision on test_dataset with trained f.c. layer', metrics['precision'])\n",
    "writer.add_scalar(f'Recall on test_dataset with trained f.c. layer', metrics['recall'])\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bogdanov_VU_kernel 3.8.10",
   "language": "python",
   "name": "bogdanov_vu_3.8.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
