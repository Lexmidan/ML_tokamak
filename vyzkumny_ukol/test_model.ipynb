{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing\n",
    "\n",
    "- It's just a testing ground for the model. One model is loaded and a `cmc.test_model` is applied on it.\n",
    "- As a result confusion matrix, ROC, AUROC, F1, PR curves will be generated and saved to the model's folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import confinement_mode_classifier as cmc\n",
    "import torchvision\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import re\n",
    "\n",
    "path = Path(os.getcwd())\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dir_path = f'{path}/data/LH_alpha'\n",
    "file_names = os.listdir(data_dir_path)\n",
    "\n",
    "\n",
    "#Chose what shots will be used in notebook. Removed shots has different dimensions\n",
    "batch_size = 32\n",
    "\n",
    "shot_numbers = [re.search(r'shot_(\\d+)', file_name).group(1) for file_name in file_names]\n",
    "removed_shots = ['19915', '19925', '13182', '20009', '20112', \n",
    "                 '20143', '20145', '20146', '20147', '20144', '20098']\n",
    "shot_numbers = [valid_shot for valid_shot in shot_numbers if valid_shot not in removed_shots]\n",
    "\n",
    "shots_for_testing = ['18130', '16773', '16534', '19094', '18133', '17837', '18128']\n",
    "shots_for_validation = ['16769', '19379', '18057', '18132', '18261', '18267', '18260']\n",
    "\n",
    "\n",
    "shot_df, test_df, _, _ = cmc.load_and_split_dataframes(path, shot_numbers, shots_for_testing, \n",
    "                                                       shots_for_validation=shots_for_validation,\n",
    "                                                       use_ELMS=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate a single camera model\n",
    "pretrained_model = torchvision.models.resnet18(weights='IMAGENET1K_V1', )\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = pretrained_model.fc.in_features\n",
    "pretrained_model.fc = nn.Linear(num_ftrs, 3) #3 classes: L-mode, H-mode, ELM\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "\n",
    "#Which model to test?\n",
    "model_path = f'{path}/runs/24-02-22, 14-36-03 RIS1, onecycleLR, extended dset_last_fc'\n",
    "#TEST one camera model\n",
    "pretrained_model.load_state_dict(torch.load(f'{model_path}/model.pt'))\n",
    "pretrained_model.eval()\n",
    "pretrained_model.to(device)\n",
    "\n",
    "#TEST ensembled model\n",
    "# ensembled_model = cmc.TwoImagesModel(modelA=pretrained_model, modelB=pretrained_model, hidden_units=30).to(device)\n",
    "# ensembled_model.load_state_dict(torch.load(f'{model_path}/model.pt'))\n",
    "# ensembled_model.eval()\n",
    "# ensembled_model.to(device)\n",
    "\n",
    "test_dataloader = cmc.get_dloader(test_df, path=path, batch_size=batch_size, shuffle=False, \n",
    "                                  balance_data=False, ris_option='RIS1', num_workers=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model on unbalanced test dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'confinement_mode_classifier' from '/compass/Shared/Users/bogdanov/vyzkumny_ukol/confinement_mode_classifier.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(cmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 436/436 [00:45<00:00,  9.52it/s]\n"
     ]
    }
   ],
   "source": [
    "metrics = cmc.test_model(model_path, pretrained_model, test_dataloader, max_batch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here the model is tested on individual shots (generates time-confidence graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:00<00:00,  7.03it/s]/compass/Shared/Users/bogdanov/vyzkumny_ukol/confinement_mode_classifier.py:603: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  conf_time_fig, conf_time_ax = plt.subplots(figsize=(10,6))\n",
      "100%|██████████| 7/7 [00:01<00:00,  6.58it/s]\n"
     ]
    }
   ],
   "source": [
    "shots_for_testing = list(map(int,shots_for_testing))\n",
    "img_path = cmc.per_shot_test(path=model_path, shots=shots_for_testing, results_df=metrics['prediction_df'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bogdanov_VU_kernel 3.8.10",
   "language": "python",
   "name": "bogdanov_vu_3.8.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
